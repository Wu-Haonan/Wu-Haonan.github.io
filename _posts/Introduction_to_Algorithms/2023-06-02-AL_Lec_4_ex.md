---
layout: article
title: Exercises in Lecture 4
tags: Introduction_to_Algorithms
aside:
  toc: true
sidebar:
  nav: Introduction_to_Algorithms
---

[TOC]

# Heapsort

In this exercise part, we gonna introduce Heapsort. Heapsort's running time is ${ O (n\lg n) }$. Just like Quicksort, heapsort sorts array <b><font color="red">in place</font></b>. 

Heapsort also introduce aother useful algorithm design techinque: a kind of data structure called "<b><font color="red">heap</font></b>". Here the "heap" can be used in Heapsort and Priority queue. Let's move forward to its content!

<!--more-->

## Heap

The (binary) heap data structure is an array object that we can view as a nearly complete binary tree. An array ${ A }$ that represents a heap is an object with two attributes: ${ A.length }$, which (as usual) gives the number of elements in the array, and ${ A.heap-size }$, which represents how many elements in the heap are stored within array ${ A }$. That is ${ 0 \leq A.heap-size \leq  A.length}$

<p align="center">
    <img src="/post_image/Introduction_to_Algorithm/Lec_4
/Heap.PNG" width="70%">
</p>

__An example of Heap[^1]__

For each note ${ i }$, we can easily compute the  indices of its parent, left child and right child:

{% highlight pseudocode linenos %}
PARENT (i)
    return [i/2]
LEFT (i)
    return 2i
RIGHT (i)
    return 2i+1
{% endhighlight %}

<details><summary>It's easy to check the anwser!</summary>

--- 

Suppose note ${ i }$ is the ${ x^{th} }$ note in the ${ k^{th} }$ level. So, ${ i = \sum_{j=1}^{k-1} 2^{j-1} +x = 2^{k-1} - 1 +x  }$. For the left child of note ${ i }$, the number of notes from ${ 1^{st} }$ to ${ k^{th} }$ level is ${ 2^{k} - 1 }$, and the remaining notes before left child in ${ (k+1)^{th} }$ level is ${ [2(x-1) + 1]^{th} }$ note. So the order of left child is ${ 2^{k} - 1 + 2x -2 + 1   = 2^{k} + 2x -2 = 2i}$. So, it's easy to check the indices of right child and parent. 

---

</details>

There are two kinds of binary heaps: <b><font color="red">max-heaps</font></b> and <b><font color="red">min-heaps</font></b>. In a max-heap, the <b>max-heap property</b> is that for every node ${ i }$, other than the root,

<center>$$
A[\text{PARENT}(i)] \geq A[i],
$$</center>

That means the largest value is stored at the root (Note: we use max-heap in Heapsort algorithm). A min-heap is organized in the opposite way: the <b>min-heap property</b> is that for every node ${ i }$ other than the root,

<center>$$
A[\text{PARENT}(i)] \leq A[1].
$$</center>

The smallest element in a min-heap is at the root. And, it's easy to check the <b>height</b> of the tree is ${ \Theta(\lg n) }$.

In the following, we gonna talk about how Heapsort works. We have several proceduces

* MAX-HEAPIFY proceduce, which runs in ${ O(\lg n) }$ time, is the key to maintaning the max-heap property. 

* BUILD_MAX_HEAP procedure, which runs in linear time, procedures a max-heap from an unordered input array. 

* The HEAPSORT procedure, which runs in ${ \Theta(n \lg n) }$ time, sorts an array in place.

## Maintaining the heap property

Assume that the binary trees rooted at ${ \text{LEFT}(i) }$ and ${ \text{RIGHT}(i) }$ are max-heaps, but that ${ A[i] }$ might be smaller than its children. So we can call Max-property here to maintain the heap property, the pseudocode is shown below

{% highlight pseudocode linenos %}
MAX-HEAPIFY(A,i)
    l = LEFT(i)
    r = RIGHT(i)
    if l <= A.heap-size and A[l] > A[i]
        largest  = l // "largest" stores the index of largest element
    else 
        largest = i
    if r <= A.heap-size and A[r] > A[largest]
        largest = r
    if largest != i
        exchange A[i] with A[largest]
        MAX-HEAPIFY(A, largest)
{% endhighlight %}

The idea of MAX-HEAPIFY is clear, we just compare the value of ${ A[i], A[r], A[l] }$, if ${ A[i] }$ not the largest one, we exchange it to the largest one of its children. The exchange may cause that the binary heap of ${ A[largest]  }$ violates the heap property, so we need to call MAX-HEAPIFY recursively on that subtree.

Now, we analyze the running time of MAX-HEAPIFY for a tree with ${ n }$ notes, the cost of this procedure is from the exchange time ${ \Theta(1) }$ and the time to recursively run MAX-HEAPIFY on a subtree. 

<p align="center">
    <img src="/post_image/Introduction_to_Algorithm/Lec_4
/MAX-HEAPIFY_worst_case.png" width="70%">
</p>

<details><summary>The worst case of runing MAX-HEAPIFY on subtree happens when the bottom level of the tree is exactly half full. The children's subtrees have size at most ${ 2n/3 }$. </summary>

---

For the binary tree at root ${ i }$, the worst case is that the left subtree takes a biggest part of the whole tree, which means the left subtree contains one more level than right subtree. We can suppose the height of right subtree is ${ k }$, so the number of left subtree and right subtree are ${ 2^{k+1}-1 }$ and ${ 2^k -1 }$, so the ratio of left subtree over whole tree is 

<center>$$
\begin{equation}
\begin{aligned}
\frac{\text{Left subtree}}{n} &= \frac{2^{k+1}-1}{2^{k+1}-1 + 2^k -1 +1} \\ 
&=  \frac{2 \cdot 2^{k}-1}{3\cdot 2^{k} -1 } \\
& \leq 2/3
\end{aligned}
\end{equation}
$$</center>

---

</details>

Therefore, the recurrence of ${ T(n) }$ is 

<center>$$
T(n) \leq T(2n/3) + \Theta(1)
$$</center> 

Accoding to Master Theorem case 2, ${ n^{\log_{3/2} 1 } = 1}$, ${ f(n) = \Theta(1 (\lg n)^{0}) }$. So, ${ T(n) = \Theta(\lg n) }$

## Building a heap

We can use the procedure MAX-HEAPIFY in a bottom-up manner to convert an array ${ A[1...n]  }$, where ${ n = A.length }$, into a <b>max-heap</b>. For all the leaves, they are already a max-heap with just one element. And, we can call MAX-HEAPIFY to rearrange the PARENT of these leaves. From bottom to the root, we can build a max-heap. Here we put up the pseudo code of BUILD-MAX-HEAP

{% highlight pseudocode linenos %}
BUILD-MAX_HEAP(A)
    A.heap-size = A.length
    for i = [A.length/2] downto 1
        MAX-HEAPIFY(A,i)
{% endhighlight %}

<details><summary>We can easily check the indices of leaves are ${ \lfloor n/2 \rfloor + 1, \lfloor n/2 \rfloor + 2, \cdots, n  }$. So, the loop begins from ${ \lfloor A.length/2 \rfloor }$</summary>

---

For node ${ n }$, we know it's the last leaf in the tree, so its PARENT is the last note which has a child / children. So, the first leaves number is ${ \text{PARENT}(n) + 1 =   \lfloor n/2 \rfloor + 1}$

---

</details>

For BUILD-MAX-HEAPIFY procedure, we can calculate the total cost of its runing time. We already know the runing time of MAX-HEAPIFY is ${ O(\lg n) }$, if we denote the height of tree as ${ h }$, the runing time is ${ O(h) }$.

<details><summary>Because we call MAX-HEAPIFY from bottom to root, in each level, the number of notes whose height are ${ h }$ is ${ \lceil \frac{n}{2^{h+1}} \rceil}$. </summary>

---

Because, the notes whose height is ${ h }$, means they lay in the ${ \lfloor \lg n \rfloor ^{th} - h}$ or ${ (\lfloor \lg n \rfloor - 1 - h )^{th} }$. So, there are at most ${ \lceil2 ^ {\lfloor \lg n \rfloor ^{th} - h - 1} \rceil = \lceil \frac{n}{2^{h+1}} \rceil}$ notes whose height is ${ h }$ (Note, the ${ k^{th} }$ level have ${ 2^{k-1} }$ notes). 

---
</details>

Therefore, we can get the running time

<center>$$
\begin{equation}
\begin{aligned}
T(n) &= \sum_{h=1}^{\lfloor \lg n \rfloor} = \lceil \frac{n}{2^{h+1}} \rceil O(h) \\
& = O\left( n \sum_{h=1}^{\lfloor \lg n \rfloor} \frac{h}{2^{h+1}} \right) \\
& = O\left( n \left( 2\cdot \sum_{h=1}^{\lfloor \lg n \rfloor} \frac{h}{2^{h+1}} - \sum_{h=1}^{\lfloor \lg n \rfloor} \frac{h}{2^{h+1}}\right) \right) \\
& =  O\left( n \left( \sum_{h=1}^{\lfloor \lg n \rfloor} \frac{h}{2^{h}} - \sum_{h=1}^{\lfloor \lg n \rfloor} \frac{h}{2^{h+1}}\right) \right) \\
&= O\left( n \left( \frac{1}{2}+  \sum_{h=1}^{\lfloor \lg n \rfloor - 1} \frac{h+1}{2^{h+1}} - \sum_{h=1}^{\lfloor \lg n \rfloor} \frac{h}{2^{h+1}}\right) \right) \\
&= O\left( n \left( \frac{1}{2} -  \frac{\lfloor \lg n \rfloor}{2^{\lfloor \lg n \rfloor+1}} + \sum_{h=1}^{\lfloor \lg n \rfloor - 1} \frac{h+1}{2^{h+1}} -  \frac{h}{2^{h+1}} \right) \right) \\
& = O\left(n \left(\frac{1}{2} - \frac{\lfloor \lg n \rfloor}{2 \cdot n} + \frac{1}{2} \cdot (1- (\frac{1}{2})^{\lfloor \lg n \rfloor -1}) \right)\right) \\
& = O\left(n \left(\frac{1}{2} - \frac{\lfloor \lg n \rfloor}{2 \cdot n} + \frac{1}{2} -  \frac{1}{n}) \right)\right) \\
& = O(n - \lg n - 1 ) = O(n)
\end{aligned}
\end{equation}
$$</center>

Thus, through our analysis, the runing time of BUILD-MAX-HEAP is linear.

## Heapsort Algorithm

We use BUILD-MAX-HEAP to make ${ A[1...n] }$ into a max-heap. And, we can exract ${ A[1] }$ which is already the largest element. We exchange ${ A[1] }$ and ${ A[n] }$. Then, we consider the array ${ A[1...n-1] }$, in this time, the root is ${ A[1] }$, which may not satisfy max-heap property, but the two subtree still statisfy it, and we can maintain it by MAX-HEAPIFY. Keep doing it, until the heap-size downto 2. Here is the pseudocode

{% highlight psedocode linenos %}
HEAPSORT(A)
    for i = A.length downto 2
        exchange A[1] with A[i]
        A.heap-size = A.heap-size - 1
        MAX-HEAPIFY(A,1)
{% endhighlight %}

It's easy to check the runing time is ${ T(n) = O(n) + n O(\lg n) = O(n \lg n) }$.

# Priority queues

A <b><font color="red">priority queue</font></b> is a data structure for maintaining a set ${ S }$ of elements, each with an associated value called a <b>key</b>. A <b>max-priority queue</b> supports the following operations:

${ \text{INSERT}(S,x) }$ inserts the element ${ x }$ into the set ${ S, }$ which is equivalent to the operation ${ S = S \cup \{x\}. }$

${ \text{MAXIMUM}(S) }$ returns the element of ${ S }$ with the largest key.

${ \text{EXTRACT-MAX}(S) }$ removes and returns the element of ${ S }$ with the largest key.

${ \text{INCREASE-KEY}(S,x,k) }$ increases the value of element ${ x }$'s <b>key</b> to the new value k, which is assumed to be at least as large ${ x }$'s current key value.


# Hat-check problem

Use indicator random variables to solve the following problem, which is known as the hat-check problem. Each of ${ n }$ customers gives a hat to a hat-check person at a restaurant. The hat-check person gives the hats back to the customers in a random order. What is the expected number of customers who get back their hats?

Let ${ X_i }$ be the indicator random variable that indicates whether the customer ${ i }$ gets his hat back

<center>$$
\begin{equation}
X_i = 
\begin{cases}
1 \quad \text{customer } i \text{ gets hat,} \\
0 \quad \text{customer } i \text{ not get hat.} \\
\end{cases}
\end{equation}
$$</center>

So, the number of customers who get their hats back is ${ \sum_{i=1}^n X_i}$. Therefore the expected number is 

<center>$$
\begin{equation}
\begin{aligned}
E \left[   \sum_{i=1}^n X_i\right] &= \sum_{i=1}^n E \left[ X_i\right] \\
& = \sum_{i=1}^n \left(0\cdot P(X_i = 0) + 1 \cdot P(X_i = 1) \right)\\
& = \sum_{i=1}^n \frac{1}{n} \\
& = 1
\end{aligned}
\end{equation}
$$</center>

[^1]: Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2022). <i>Introduction to algorithms.</i> MIT press.