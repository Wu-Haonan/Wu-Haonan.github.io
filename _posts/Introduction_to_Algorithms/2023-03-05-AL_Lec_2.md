---
layout: article
title: Asymptotic Notation; Recurrences; Substitution, Master Method
tags: Introduction_to_Algorithms
aside:
  toc: true
sidebar:
  nav: Introduction_to_Algorithms
---

This lecture is going to develop asymptotic notation mathematically and how to solve recurrences.

<!--more-->

# Asymptotic notation

## ${ O }$ notation

${ f(n) = O (g(n)) }$ means there are consts ${ c>0, n_0 > 0  }$ such that (assume ${ f(n)  }$ is non-negtive)

<center>$$
0 \leq f(n) \leq cg(n), \text{ for all } n \geq n_0
$$</center>

Ex. ${ 2 n^2 = O(n^3) }$

Notice, ${ f(n) = O (g(n)) }$ doesn't means ${ g(n) = O(f(n)) }$. The ${ O }$ notation is <b>not asymmetric</b>. Actually, we can treat ${ O(g(n)) }$ as a set of funtions. 

<center>$$
O(g(n)) = \left\{ f(n):  \text{ there are consts } c>0, n_0 >0 \text{ such that } 0 \leq f(n) \leq cg(n), \text{ for all } n \geq n_0 \right\} 
$$</center>

So, when we talk about ${ f(n) = O(g(n)) }$, actually, it means ${ f(n) \in O(g(n)) }$

### Macro convention

A set in a formula represents an anonymous funtion in that set.

Ex. ${ f(n) = n^3 + O(n^2) }$

That means there is a funtion ${ h(n) \in O(n^2) }$ such that ${ f(n)=n^3+ h(n) }$

Ex. ${ n^2+O(n) = O(n^2) }$

That means for any ${ f(n)\in O(n) }$, there is an ${ h(n)\in O(n^2) }$, such that ${ n^2+f(n)=h(n) }$.

## ${ \Omega }$ notation

Define: ${ \Omega(g(n)) =\left\\{ f(n):  \text{ there are consts } c>0, n_0 >0 \text{ such that } 0 \leq g(n) \leq cf(n), \text{ for all } n \geq n_0 \right\\}  }$

Ex. ${ \sqrt n = \Omega(\lg n) }$

## ${ \Theta }$ notation

Define: ${ \Theta (g(n)) = O(g(n)) \cap \Omega (g(n)) }$

## ${ o }$ and ${ \omega }$ notation

Define: ${ o(g(n)) = \left\\{ f(n): \text{ for any const } c>0, \text{ there exists const } n_0 >0 \text{ such that } 0 \leq f(n) \leq cg(n), \text{ for all } n \geq n_0 \right\\}  }$

Define: ${ \omega(g(n)) = \left\\{ f(n): \text{ for any const } c>0, \text{ there exists const } n_0 >0 \text{ such that } 0 \leq g(n) \leq cf(n), \text{ for all } n \geq n_0 \right\\}  }$

Ex. ${ 2n^2 = o(n^3) }$,

Ex. ${ \frac{1}{2}n^2 = \Theta(n^2) }$ but ${ \neq o(n^2) }$

# Solving recurrences

## Substitution method

1. Guess the form of the solution

2. Verify by induction

3. Solve for consts

Ex. Solve the following recurrences

<center>$$
T(n) = 
\begin{cases}
4 T(n/2)+n, n>1\\
\Theta(1), n = 1
\end{cases}
$$</center>

<b>Ans</b>:

1. Guess: ${ T(n) = O(n^3) }$

2. Induction: Assume ${ k<n }$ is correct, that is

<center>$$
T(k) \leq ck^3 \text{ for } k < n
$$</center>

3. Now, let's check 

<center>$$
T(n) = 4T(n/2) +n \leq 4c(n/2)^3+n = \frac{c}{2}n^3+n
$$</center>

So, ${ T(n) \leq cn^3 - \left(\frac{c}{2}n^3-n\right)  }$, which at most ${ cn^3 }$ when ${ \frac{c}{2}n^3-n \geq 0}$. That is we can find ${ c }$ and ${n_0 }$, such that ${ T(n) \in O(n^3) }$, e.g. ${ c\geq1,  n_0=1 }$

The base case is trivial, it's easy to find some sufficient large ${ c }$, such that

<center>$$
T(1)=\Theta(1) \leq c
$$</center>

<details open><summary>Actually, the above proof is from the class video, I thought it's not rigour mathematically. Therefore I will show another proof in the following.</summary>

Let ${ C=\max \left\{\frac{1}{2},\Theta(1)\right\} }$

when ${ n=1 }$, ${ T(n)=\Theta(1)\cdot n^3\leq Cn^3 }$

when ${ n \leq k-1 }$, assume for ${ T(n)\leq Cn^3 }$

consider ${ n = k }$, that is

<center>$$
T(k) = 4T(k/2)+k \leq C\cdot 4 \cdot \left(\frac{k}{2}\right)^3 + k =C\cdot \frac{k^3}{2}+k = Ck^3 - \left(C\cdot \frac{k^3}{2}-k\right)
$$</center>

Because ${ C\geq \frac{1}{2} }$, it's trivial to get ${ C\cdot \frac{k^3}{2}-k \geq 0 }$ 

Therefore, we can get the conclusion, for all ${n\in \mathbb{N}^+  , T(n)\leq Cn^3}$. That is ${ T(n) = O (n^3) }$
</details>

<details open><summary>We just prove a strong conclusion, that is, for all ${ n\in \mathbb{N}^+ }$, we can get ${ T(n)\leq Cn^3 }$. Actually, we just need to prove that when ${ n\geq n_0 }$, we can find constant ${ C }$ to satisfy ${ T(n)\leq Cn^3 }$. Actually, we can prove there exists ${ n_0 >0 }$, such that ${ T(n)\leq 2n^3}$ when ${n>n_0 }$, that is ${ C=2 }$ (in fact ${ C>2 }$ is also OK). This is another strong conclusion, but for ${ C }$. </summary>

Let ${ n_0 = \max\{1,\Theta(1)\} }$.

First, we prove ${ n=n_0 }$ is right

<center>$$
\begin{equation}
\begin{aligned}
T(n_0) &= 4(T(n_0/2))+n_0 \\
&= 4\left(4\left(T(n_0/4)\right)+n_0/2\right)+n_0 \\
&= \cdots \\
&= 4^{\lg_2 n_0} \cdot \Theta(1) + n_0 \cdot (1+2+\cdots+2^{\lg_2 n_0})\\
&={n_0}^2\cdot \Theta(1) + n_0 \cdot \frac{1-2^{\lg_2 n_0}}{1-2} \\
&= {n_0}^2\cdot \Theta(1) + (n_0 - 1)n_0
\end{aligned}
\end{equation}
$$</center>

Because, ${ n_0 = \max\{1,\Theta(1)\} }$ that is ${ n_0 \geq \Theta(1) }$.

Therefore, we can get 

<center>$$
\begin{equation}
\begin{aligned}
T(n_0) &= {n_0}^2\cdot \Theta(1) + (n_0 - 1)n_0 \\
&\leq n_0^3 +n_0^2 -n_0
\end{aligned}
\end{equation}
$$</center>

In the meantime, ${ n_0 \geq 1 }$, so ${ n_0^2-n_0 \leq n_0^3 }$. Then we can get

<center>$$
\begin{equation}
\begin{aligned}
T(n_0) &\leq n_0^3 +n_0^2 -n_0 \\
&\leq 2n_0^3
\end{aligned}
\end{equation}
$$</center>

So, ${ n=n_0 }$ is corrected. Assume all the cases of ${ n <k, k>n_0 }$ satisfy ${ T(n)\leq 2n^3 }$, let's check ${ n=k }$:

<center>$$
T(k) = 4T(k/2)+k \leq 4 \left(\frac{k}{2}\right)^3 + k \leq \frac{1}{2}\cdot k^3 +k \leq 2k^3
$$</center>

</details>

To sum up, in fact the prove from video is not very rigor, becasue the const ${ C }$ is not the same one in the cases of ${ n>1 }$ and ${n=1 }$. For the following proof I gived, the clue of my proof is fixing ${ C }$ or ${ n_0 }$ to prove ${ T(n) = O(n^3) }$.

In the following, we will prove that ${ T(n) = O(n^2) }$, 

1. Guess: ${ T(n) = O(n^2) }$

2. Induction: Assume ${ k<n }$ is correct, that is 

<center>$$
T(k) \leq c_1 \cdot k^2 -c_2 \cdot k \quad \text{ for } k < n
$$</center>

<details><summary>Why we choose the assumption ${ T(k) \leq c_1 \cdot k^2 -c_2 \cdot k }$? </summary>
Out of intuition, maybe we will figure out ${ T(k) \leq c \cdot k^2 }$ at first, but we will find that ${T(n) \leq cn^2 + n}$, so we can not go on our induction.

Therefore, this form may give us some inspiration, to use a stronger assumption to do induction.
</details>

3. Now, let's check 

<center>$$
\begin{equation}
\begin{aligned}
T(n) &= 4T(n/2)+n \\
&\leq 4\left(c_1 (n/2)^2-c_2 (n/2)\right) + n \\
&= c_1 n^2 -2c_2\cdot n +n \\
&= c_1 n^2 -c_2 n - (c_2-1) \cdot n
\end{aligned}
\end{equation}
$$</center>

So, here we can let ${ c_2 > 1 }$ to guarantee ${ (c_2 -1)\cdot n > 0 }$. So we can finish our induction. Besides, for the base case

<center>$$
\Theta(1) \leq c_1 -c_2
$$</center> 

Therefore, we need ${ c_2 >1 }$ and ${ c_1 > \Theta(1) + c_2 }$.

## Recursion-tree method

Recursion-tree usually works and can give us an intuition to know the answer, but it's slightly non-rigorous!

Technically, we should use resursion-tree method to find the answer and use substitution method to prove it rigorously.

Ex. ${ T(n)=T(n/4)+T(n/2)+n^2 }$

We can build a "Recursion Tree" as follow

<p align="center">
    <img src="/post_image/Introduction_to_Algorithm/Lec_2/recursion_tree.png" width="70%">
</p>

<details><summary>First, we can know that the number of leaves is less than ${ n }$. </summary>
If we divide ${ T(n) }$ to four ${ T(n/4) }$ or two ${ T(n/2) }$, the number of leaves will be ${ n }$. But, here ${ n/4 + n/2 = 3n/4 <n  }$, so the number of leaves must less than ${ n }$. 
</details>

Then, we will calculate the sum of tree level by level. Through observation, we find that the sums of each level construct a geometric series (see the following figure).

<p align="center">
    <img src="/post_image/Introduction_to_Algorithm/Lec_2/sum_of_tree.png" width="70%">
</p>

Therefore, we can calculate the upper bound of ${ T(n) }$ (the height of tree is a finite number, but we treat it as a infinite geometric series.)

<center>$$
\begin{equation}
\begin{aligned}
T(n) &< n^2 \cdot \sum_{i=0}^{\infty} \left(\frac{5}{16}\right)^i + \Theta(1) \cdot n \\
&= n^2 \cdot \lim_{i\rightarrow \infty} \frac{1-\left(\frac{5}{16}\right)^i}{1-\frac{5}{16}}+\Theta(1) \cdot n\\
&= \frac{16}{11} \cdot n^2 + \Theta(1) \cdot n \\
&= O(n^2)
\end{aligned}
\end{equation}
$$</center>

In the meantime, it's easy to get ${ T(n)>n^2 }$, so ${ T(n) = o(n^2) }$. Therefore  ${ T(n) = \Theta(n^2) }$.

## Master method

We can treat the Master method as an application of the recursion-tree method. In detail, we apply resursion-tree method to a particular family (as below) of recurrences to get Master theorem.

<center>$$
T(n) = aT(n/b) + f(n) \quad \text{ where } a \geq 1, b>1, \text{ and } f(n) \text{ is asymptotically positive} 
$$</center>

Note! Asymptotically positive: there exists some ${ n_0 }$, when ${ n>n_0, f(n) >0 }$.

Compare ${ f(n) }$ with ${ n^{\log_b a} }$

<b>Case \#1</b>: ${ f(n) = O\left(n^{\log_b a - \varepsilon}\right) }$ for some ${ \varepsilon >0 }$.

${\Rightarrow}$ ${ T(n) = \Theta\left(n^{\log_b a}\right) }$ 

<b>Case \#2</b>: ${ f(n) = \Theta\left(n^{\log_b a}(\lg n)^k\right) }$ for some ${ k\geq 0 }$

${\Rightarrow}$ ${ T(n) = \Theta\left(n^{\log_b a}(\lg n)^{k+1}\right) }$

<b>Case \#3</b>: ${ f(n)=\Omega(n^{\log_b a+\varepsilon}) }$, for some ${ \varepsilon >0 }$. And ${ af(n/b)\leq (1-\varepsilon')\cdot f(n) }$ for some ${ \varepsilon' >0 }$

${\Rightarrow}$ ${ T(n) = \Theta\left(f(n)\right) }$

Ex. ${ T(n)=4T(n/2)+n }$

Ans: Here ${ a=4,b=2,f(n)=n }$, compare ${ n^{\log_2 4} = n^2 }$ with ${ f(n)=n }$. ${ f(n)=O(n^{2-\varepsilon}) }$ here we can take ${ \varepsilon=1 }$. So, we are in Case \#1, that means ${ T(n)=\Theta(n^{\log_2 4})= \Theta(n^2) }$

Ex. ${ T(n)=4T(n/2)+n^2 }$

Ans: Here we are in Case \#2, because we can choose ${ k=0 }$, so ${ f(n)=n=\Theta\left(n^2(\lg n)^0\right) }$. Therefore, ${ T(n)=\Theta(n^2 \lg n) }$

Ex. ${ T(n)=4T(n/2)+n^3 }$

Ans: First, let's check

<center>$$
4f(n/2) = 4(n/2)^3 = \frac{n^3}{2} \leq \frac{1}{2} f(n)
$$</center>

Here we take ${ \varepsilon'=\frac{1}{2} }$. And ${ f(n)=n^3 = \Omega(n^{2+\varepsilon}) }$, here we can let ${ \varepsilon = 1 }$. So we are in Case \#3, then we can get ${ T(n)=\Theta(f(n))=\Theta(n^3) }$

Ex. ${ T(n)=4T(n/2)+n^2/\lg n }$. Warning: here Master method doesn't apply to it.

### Proof of Master Theorem

<p align="center">
    <img src="/post_image/Introduction_to_Algorithm/Lec_2/Master_theorem.PNG" width="80%">  
</p>

<center><small> The recursion tree generated by ${ T(n)=aT(n/b)+f(n) }$[^1]. </small></center>

[^1]: Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2022). <i>Introduction to algorithms.</i> MIT press.