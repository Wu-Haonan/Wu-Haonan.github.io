---
layout: article
title: Lecture 16:Implementations of the simplex method
tags: Linear_Programming
aside:
  toc: true
sidebar:
  nav: Linear_Programming
---

This blog is talking about the naïve implementation of simplex method and then focus on how to speed up simplex method. And the second idea induce the Simplex Tableau implementation.

<!--more--> 

Now, we analysis the computation complexity in current simplex algorithm.  

1. Inverting matrix $[B]_{m \times m}$ takes $O(m^3)$ arithmetic operations.

2. Solving an $m \times m$ linear system takes $O(m^3)$ arithmetic operations. 

3. Computing $[B][\bar{b}]$ takes $O(m^2)$ arithmetic operations.

4. Computing $\bar{p}^\top \bar{b}$ takes $O(m)$ arithmetic operations.

# Naïve Implementation

At the begin of iteration, we have the indices $B(1), B(2), ..., B(m)$ of the current basic variables and the basis matrix $B$.

We compute $\bar{p}^\top := c_B^\top B^{-1}$, which consumes $O(m^3)$ operations. The vector $\bar{p}$ is called the **vector of simplex multipliers** associated with the basis matrix $B$.

Then the reduced cost $\tilde{c}_i = c_i - c_B^T B^{-1} A_i = c_i - \bar{p}^\top A_i$, which takes $O(mn)$ operations. 

Find a (non-basic) variable $x_j$ with negative reduced cost $\tilde{c}_j < 0$. The corresponding column $A_j$ is selected to enter the basis.

Solve $B\bar{\mu} = \bar{A_j}$ to find $\bar{\mu} = B^{-1} \bar{A}_j$ from which we get the direction $\bar{d}$ along which we will be moving away from the current basis feasible solution. (But, here we don't need to compute $B^{-1}$ again).

$$
\bar{d} = \begin{bmatrix}
\bar{d}_B \\
\bar{d}_N
\end{bmatrix}
= \begin{bmatrix}
- \bar{\mu} \\
\bar{e}_j
\end{bmatrix}
$$

Finally, determine $\theta^*$ and the variable $x_{B(\ell)}$ that will exit the basis and construct the new basis solution.

$$
\theta^* = \min\limits_{i \in \{1,2,\cdots,m\} \text{ s.t. } \mu_i > 0} \left( \frac{x_{B(i)}}{u_i} \right) = \frac{x_{B(\ell)}}{\mu_{\ell}}
$$

Total computational effort of a simplex iteration: $O(m^3 + mn)$

# Revised Implementation

In this revised implementation we can finish each loop only in $O(m^2 + mn)$.



At begin of iteration, make the matrix $B^{-1}$ available. Then compute $\bar{p}^T = \bar{c}_B^\top B^{-1}$ and $\bar{\mu} = B^{-1} \bar{A}_j$. Now will find another way updating the matrix $B^{-1}$ each time more efficient.

Basis matrix:
$$
B = \begin{bmatrix}
\bar{A}_{B(1)} & \cdots & \bar{A}_{B(\ell-1)} & \bar{A}_{B(\ell)} & \bar{A}_{B(\ell+1)} & \cdots & \bar{A}_{B(m)}
\end{bmatrix}
$$

Updated basis matrix:
$$
B' = \begin{bmatrix}
\bar{A}_{B(1)} & \cdots & \bar{A}_{B(\ell-1)} & \bar{A}_j & \bar{A}_{B(\ell+1)} & \cdots & \bar{A}_{B(m)}
\end{bmatrix}
$$

Key idea: Use knowledge of $B^{-1}$ to simplify the computation of $B'^{-1}$.

**Definition:** Any operation on a matrix $M$ of type "replace the $i^{th}$ row of $M$ by itself plus $\beta$ times the $j^{th}$ row of $M$" is called **an elementary row operation** on the matrix $M$.

We see that multiplying the $j^{th}$ row by $\beta$ and adding it to the $i^{th}$ row (for $i \neq j$) is the same as left-multiplying by the matrix $Q = I + D_{ij}$, where $D_{ij}$ is a matrix with all entries equal to zero, except for the $(i,j)\text{th}$ entry which is equal to $\beta$. The determinant of such a matrix $Q$ is equal to 1 and, therefore, $Q$ is **invertible**.

Suppose now that we apply a sequence of $K$ elementary row operations and that the $k^{th}$ such operation corresponds to left-multiplication by a certain invertible matrix $Q_k$. Then, the sequence of these elementary row operations is the same as left-multiplication by the invertible matrix $Q_KQ_{K-1}\cdots Q_2Q_1$. We conclude that **performing a sequence of elementary row operations on a given matrix is equivalent to left-multiplying that matrix by a certain invertible matrix**.

Since $B^{-1}B = I$, we see that $B^{-1}\bar{A}_{B(i)}$ is the $i^{th}$ unit vector $\bar{e}_i$. Using this observation, we have

$$
B^{-1}B = \begin{bmatrix}
| & | & | & | & | \\
\bar{e}_1 & \cdots & \bar{e}_{\ell-1} & \bar{\mu} & \bar{e}_{\ell+1} & \cdots & \bar{e}_m \\
| & | & | & | & |
\end{bmatrix}
= \begin{bmatrix}
1 & & \mu_1 & &  \\
   & \ddots & \vdots &  & &  \\
   & & \mu_{\ell} & & \\
   & & \vdots & \ddots & &\\
 & & \mu_{\ell} & & 1
\end{bmatrix}
$$

where $\bar{\mu} = B^{-1}\bar{A}_j$. Let us apply a sequence of elementary row operations that will change the above matrix to the identity matrix. In particular, consider the following sequence of elementary row operations.

(a) For each $i \neq \ell$, we add the $\ell^{th}$ row times $-\mu_i/\mu_{\ell}$ to the $i^{th}$ row. (Recall that $\mu_{\ell} > 0$.) This replaces $u_i$ by zero.

(b) We divide the $\ell^{th}$ row by $\mu_{\ell}$. This replaces $\mu_{\ell}$ by one.

Performing this sequence of elementary row operations is equivalent to left-multiplying $B^{-1}B'$ by a certain invertible matrix $Q$ so as to obtain $I$:

$$
Q \cdot B^{-1}B' = I 
$$

$$
Q \cdot B^{-1} = \left(B'\right)^{-1}
$$

Conclusion: Performing the elementary row operations (a) and (b) on $B^{-1}$ returns $\left(B'\right)^{-1}$.

## Iteration of the revised simplex algorithm

1. In a typical iteration, we start with a basis consisting of the basic columns $\bar{A}_{B(1)}, \cdots , \bar{A}_{B(m)}$, an associated basic feasible solution $x$, and the inverse $B^{-1}$ of the basis matrix.

2. Compute the row vector $p^\top = c_B^\top B^{-1}$ and then compute the reduced costs $\tilde{c}_j = c_j - p^\top \bar{A}_j$. If they are all nonnegative, the current basic feasible solution is optimal, and the algorithm terminates; else, choose some $j$ for which $\tilde{c}_j < 0$.

3. Compute $\mu = B^{-1} \bar{A}_j$. If no component of $\mu$ is positive, the optimal cost is $-\infty$, and the algorithm terminates.

4. If some component of $\mu$ is positive, let

$$
\theta^* = \min_{\{i=1,...,m \mid \mu_i>0\}} \frac{x_{B(i)}}{\mu_i}
$$

5. Let $\ell$ be such that $\theta^* = x_{B(\ell)}/\mu_{\ell}$. Form a new basis by replacing $\bar{A}_{B(\ell)}$ with $\bar{A}_j$. If $y$ is the new basic feasible solution, the values of the new basic variables are $y_j = \theta^*$ and $y_{B(i)} = x_{B(i)} - \theta^*\mu_i$, $i \neq \ell$.

6. Form the $m \times (m + 1)$ matrix $[B^{-1} \mid \bar{\mu}]$. Add to each one of its rows a multiple of the $\ell^{th}$ row to make the last column equal to the unit vector $\bar{e}_{\ell}$. The first $m$ columns of the result is the matrix $(B')^{-1}$.

# Tableau Implementation

Now, we will give an implementation of simplex method in **tableau**. Here, instead of maintaining and updating the matrix $B^{-1}$, we maintain and update the $m \times (n + 1)$ matrix

$$
B^{-1}\begin{bmatrix} \bar{b}  \mid A \end{bmatrix}
$$

with columns $B^{-1}\bar{b}$ and $B^{-1}\bar{A}_1, ..., B^{-1}\bar{A}_n$. This matrix is called the **simplex tableau**. Note that the column $B^{-1} \bar{b}$, called the **zeroth column**, contains the values of the basic variables. The column $B^{-1} \bar{A}_i$ is called the $i^{th}$ column of the tableau. The column $\mu = B^{-1} \bar{A}_j$, corresponding to the variable that **enters the basis** is called the **pivot column**. If the $\ell^{th}$ basic variable **exits the basis**, the $\ell^{th}$ row of the tableau is called the **pivot row**. Finally, the element belonging to both the pivot row and the pivot column is called the **pivot element**. Note that the pivot element is $\mu_{\ell}$ and is always positive (unless $\mu \leq 0$, in which case the algorithm has met the termination condition in Step 3).

The information contained in the rows of the tableau admits the following interpretation. The equality constraints are initially given to us in the form $\bar{b} = A\bar{x}$. Given the current basis matrix $B$, these equality constraints can also be expressed in the equivalent form

$$
B^{-1} \bar{b} = B^{-1}A \bar{x}
$$

which is precisely the information in the tableau. In other words, the rows of the tableau provide us with the coefficients of the equality constraints $B^{-1} \bar{b} = B^{-1}A \bar{x}$.

At the end of each iteration, we need to update the tableau $B^{-1}\begin{bmatrix} \bar{b} \mid A \end{bmatrix}$. This can be accomplished by left-multiplying the current tableau by the matrix of the revised simplex tableau with a matrix $Q$ satisfying $QB^{-1} = (B')^{-1}$. As explained earlier, this is the same as performing those elementary row operations that turn $B^{-1}$ to $(B')^{-1}$; that is, we add to each row a multiple of the pivot row to set all entries of the pivot column to zero, with the exception of the pivot element which is set to one.

Regarding the determination of the exiting column $\bar{A}_{B(\ell)}$ and the step size $\theta^*$, Steps 4 and 5 in the summary of the simplex method amount to the following: $x_{B(i)} / u_i$ is the ratio of the entry in the zeroth column of the tableau to the $i^{th}$ entry in the pivot column of the tableau. We only consider those $i$ for which $u_i$ is positive. The smallest ratio is equal to $\theta^*$ and determines $\ell$.

It is customary to augment the simplex tableau by including a top row, to be referred to as the zeroth row. The entry at the top left corner contains the value $-c_B^Tx_B$, which is the negative of the current cost. (The reason for the minus sign is that it allows for a simple update rule, as will be seen shortly.) The rest of the zeroth row is the row vector of reduced costs, that is, the vector $c' = c - c_B^TB^{-1}A$. Thus, the structure of the tableau is:


$ -c_B^TB^{-1}b $   |  $  c' - c_B^TB^{-1}A $
$ B^{-1}b $ | $ B^{-1}A $

The rule for updating the zeroth row turns out to be identical to the rule used for the other rows of the tableau: add a multiple of the pivot row to the zeroth row to set the reduced cost of the entering variable to zero. We will now verify that this update rule produces the correct results for the zeroth row.

At the beginning of a typical iteration, the zeroth row is of the form

$$
[0 | c'] - g'[b | A],
$$

where $g' = c_B^TB^{-1}$. Hence, the zeroth row is equal to $[0 | c']$ plus a linear combination of the rows of $[b | A]$. Let column $j$ be the pivot column, and row $\ell$ be the pivot row. Note that the pivot row is of the form $h'[b | A]$, where the vector $h'$ is the $\ell^{th}$ row of $B^{-1}$. Hence, after a multiple of the pivot row is added to the zeroth row, the updated simplex tableau is in the correct form.



