---
layout: article
title: Lecture 15:Develop of the simplex method
aside:
  toc: true
sidebar:
  nav: Linear_Programming
---

This blog is talking about how along we can move along basic feasible direction, i.e. ${ \theta }$ and talking abou the termination of Simplex Method.

<!--more--> 

Recall our assumptions: LP problem in standard form

<center>$$
\begin{aligned}
& \text{minimize} & \bar{c}^\top \bar{x} \\
& \text{subject to} & A\bar{x} = \bar{b} \\
& & \bar{x} \geq 0 \\
\end{aligned}
$$</center>

where matrix ${A}$ has <b>full row rank</b>.

We introduce an additional assumption (which will be relaxed later on):

<font color=red>Every b.f.s. is nondegenerate.</font>

Given a b.f.s. ${\bar{x}}$ (with associated basis matrix $B$) of the feasible polyhedron ${P = \{ \bar{x} \in \mathbb{R}^n \mid A\bar{x} = \bar{b} \text{ and } \bar{x} \geq \bar{0} \} } $,

**EITHER**: all reduced costs ${\bar{c}_j}$ for all nonbasic variables are nonnegative, and ${\bar{x}}$ is an optimal solution (according to [optimal certification](https://wu-haonan.github.io/2023/10/13/LP_Lec_14.html#optimal-condition)) and the simplex algorithm stops;

**OR**: the reduced cost ${\bar{c}_j}$ of a nonbasic variable ${x_j}$ is negative, and the ${j^{th}}$ <b>basic direction</b> at ${\bar{x}}$ is a feasible direction of cost decrease.

The vector ${\bar{d}_j}$ with

<center>$$
\bar{d}_j = \begin{cases}
d_{j} = 1 & \\
d_{j} = 0 & \text{for } i \neq B(1),...,B(m), j \\
d_{B} = -B^{-1}A_j & \\
\end{cases}
$$</center>

In order to lower the cost as much as possible, we then move away from the b.f.s. $\bar{x}$ along the path $\theta \rightarrow \bar{x} + \theta \bar{d}$ (for $\theta \geq 0$) as far as possible, i.e., until we reach the point $\bar{x} + \theta^*\bar{d}$ with

<center>$$
\begin{aligned}
\theta^* &= \max \{ \theta \in [0, \infty) \mid \bar{x} + \theta \bar{d} \in P \} \\
&= \max \{ \theta \in [0, \infty) \mid \bar{x} + \theta \bar{d} \geq \bar{0} \}.
\end{aligned}
$$</center>

Note: ${ A(\bar{x} + \theta \bar{d}) = \bar{b} }$
 is satisfied  ${ \forall \theta \in [0,\theta^*) }$ since  ${ A\bar{x} = \bar{b} }$ and ${ A\bar{d} = 0 }$ 

Doing so, the nonbasic variable $x_j$ becomes positive while all other nonbasic variables remain zero â€” we say that $x_j$ (or $A_j$) <b>enters or is brought into the basis</b>.

The reduction in cost resulting from the move from $\bar{x}$ to $\bar{x} + \theta \bar{d}$ is

<center>$$
\bar{c}^\top(x+\theta \bar{d}) - \bar{c}^\top \bar{x} = \bar{c}^\top \theta \bar{d} = \theta (\bar{c}_j + \bar{c}_B^\top \bar{B}^{-1} \bar{d}_B) = \theta (\bar{c}_j - \bar{c}_B^\top \bar{B}^{-1} A_j) = \theta \tilde{c}_j
$$</center>

# How to compute ${\theta^*}$?

The path $\theta \mapsto \bar{x}+\theta \bar{d}$ (with $\theta \geq 0$) exits the feasible set $P$ when a nonnegativity constraint is about to be violated.

<b>EITHER $\bar{d} \geq 0$</b> and then $\bar{x}+\theta \bar{d} \geq 0$ for all $\theta \in [0,\infty)$ so that $\bar{x}+\theta \bar{d}$ never exits $P$ and we set $\theta^* = \infty$

<b>OR $\bar{d}_i < 0$ for some $i$</b> and then

$\theta^* = \max \\{ \theta \in [0,\infty) \mid \bar{x}+\theta \bar{d} \geq 0 \\}$

- For each $k$ s.t. $\bar{d}_k \geq 0$, we have $\bar{x}_k+\theta \bar{d}_k \geq 0$ for all $\theta \geq 0$

- For each $k$ s.t. $\bar{d}_k < 0$, we have $\theta \leq -\frac{\bar{x}_k}{\bar{d}_k}$

<center>$$
\begin{aligned}
\theta^* &= \max \left\{ \theta \in [0,\infty) \bigg| \theta = -\frac{\bar{x}_k}{\bar{d}_k} \text{ if } \bar{d}_k < 0 \right\} \\
&= \min_{\substack{k \in \{1,2,\cdots,n\} \\ \text{ s.t. } d_k <0 }} \left( -\frac{\bar{x}_k}{\bar{d}_k} \right)\\
& \min_{\substack{i \in \{1,2,\cdots,m\} \\ \text{ s.t. } d_{B(i)} <0 }} \left( -\frac{\bar{x}_{B(i)}}{\bar{d}_{B(i)}} \right)
\end{aligned}
$$</center>

where $\{1,...,n\}^+$ represents the set of indices for which $\bar{d}_k$ is positive.

Conclusion:

<center>$$
\theta^* = 
\begin{cases} 
\infty & \text{if } \bar{d} \geq 0 \\
\min_{\substack{i \in \{1,2,\cdots,m\} \\ \text{ s.t. } d_{B(i)} <0 }} \left( -\frac{\bar{x}_{B(i)}}{\bar{d}_{B(i)}} \right) & \text{otherwise}
\end{cases}
$$</center>

Thus, if $\theta^\*$ is finite, $\theta^\* = \frac{-\bar{x}\_{B(i)}}{\bar{d}\_{B(i)}}$ for some $i \in \{1,...,m\}$ (with $\bar{d}\_{B(i)} < 0$), and we have $\bar{x}\_{B(i)} + \theta^* \bar{d}\_{B(i)} = 0$.

The variable $\bar{x}_{B(i)}$, which was basic at the b.f.s. $\bar{x}$, has become zero at $\bar{x}' := \bar{x} + \theta^* \bar{d}$, whereas the variable $x_j$, which was nonbasic at the b.f.s. $\bar{x}$, has become positive at $\bar{x}' := \bar{x} + \theta^* \bar{d}$.

This suggests that ${x_j}$ should replace ${\bar{x}_{B(i)}}$ in the basis.

# What's the updating basic matrix

Let $\bar{B} = \begin{bmatrix}\bar{A}\_{B(1)} & \bar{A}\_{B(2)} & \cdots &\bar{A}\_{B(\ell-1)} & \bar{A}\_{B(\ell)} &\bar{A}\_{B(\ell+1)} &\cdots &\bar{A}\_{B(m)} \end{bmatrix}$ be the basis matrix corresponding to the b.f.s. $\bar{x}$.

Let $\bar{B}' = \begin{bmatrix}\bar{A}\_{B(1)} & \bar{A}\_{B(2)} & \cdots &\bar{A}\_{B(\ell-1)} & \bar{A}\_{j} &\bar{A}\_{B(\ell+1)} &\cdots &\bar{A}\_{B(m)} \end{bmatrix}$ be the matrix obtained from ${ B }$ by replacing the column ${ \bar{A}\_{B(\ell)} }$ by ${ \bar{A}\_{j} }$

# Iteration of Simplex algorithm

## Terminates in finite steps?

## Degeneracy in Simplex Method