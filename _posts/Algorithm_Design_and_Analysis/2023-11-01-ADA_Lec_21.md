---
layout: article
title: Rounding and Dynamic Programming:Parallel Macines Job Scheduling
tags: Algorithm_Design_and_Analysis
aside:
  toc: true
sidebar:
  nav: Algorithm_Design_and_Analysis
---

This blog is still talking about "rounding data" strategy and dynamic programing. And this blog will focus on the bin-packing problem.

<!--more-->

# Backgroud

## Definition of Bin-Packing

Given ${ n }$ items with size ${ a_1,a_2,\cdots,a_n }$, where ${ 1 \geq a_1 \geq a_2 \geq \cdots \geq a_n \geq 0 }$. We need pack the items into bins where each bin can hold any subset of items of total size as most ${ 1 }$. And we need to minimize the number of used bins.

## Partition Problem ${ \leq_p }$ Bin-Packing

<b>Partition Problem</b>: Given ${ n }$ positive integers ${ b_1,b_2,\cdots, b_n }$, where ${ B = \sum{i=1}^n b_i  }$ is even. It's a decision problem that if we can partition the set ${ \\{1,2,\cdots n\\} }$ into two sets ${ S }$ and ${ T }$ s.t. ${ \sum_{i\in S} b_i = \sum_{i\in T} b_i}$. In fact, Partition Problem is a NP-Complete problem. (we don't prove here).

Now we will show Partition Problem ${ \leq_p }$ Bin-Packing.

We set ${ a_i = 2b_i /B }$, and use algorithm of Bin-Packing to check if we can pack all pieces into two bins.

# Asymptotic PTAS for Bin-Packing

## Definition of APTAS

<b>Definition</b>: An asymptotic polynomial time approximation scheme (APTAS) is a family of algorithms ${ A_{\epsilon} }$, along with a constant ${ c }$, where there is an algorithm for each ${ \epsilon \geq 0}$, such that ${ A_{\epsilon} }$ is a ${(1+\epsilon)+c  }$-approximation algorithm (for minimization problems) or a ${(1-\epsilon)-c  }$-approximation algorithm (for maximization problems)

## Big picture of idea

The Dynamic Programming strategy used in schueduling jobs on ${ m }$ machine inspires us. Giving target time equals to the limit of bins as ${ 1 }$. And here we need to figure out the minimum bins to be used.

Addtionally, we also divide the pieces into large and small ones.

1. Suppose we have an algorithm that can pack large pieces in at most ${ (1+\epsilon)OPT + 1 }$ bins. And we will show we can still use at most ${ (1+\epsilon)OPT + 1 }$ bins after packing the remaining small pieces. 

2. We still use the rounding strategy for following dynamic Programming, and we will show the relation between rounded instance ${ I' }$ and original input ${ I }$ satisfying ${ OPT(I') \leq OPT(I) \leq OPT(I') + k}$, ${ k }$ is a given constant depending on ${ \epsilon }$

3. We will show the Dynamic Programming will finish in polynomial time. 

## Large and small pieces

We define that a piece ${ i }$ is large if ${ a_i \geq \epsilon /2 }$, else call it small one.

* Step 1: Find packing for large items in at most ${ (1+\epsilon)OPT + 1 }$ bins.

* Step 2: Sort the small pieces in non-increasing order as their size.

* Step 3: Use first-fit algorithm, that is pick each item one by one and pack it to first bin in which it can fit.

<b>Lemma 1</b>: Suppose packing for large items is in at most ${ (1+\epsilon)OPT + 1 }$ bins, the above APTAS gives an ${ (1+\epsilon)OPT + 1 }$-approximation algorithm.

Proof. If there no extra bins used in step 3. The algorithm gives an ${ (1+\epsilon)OPT + 1 }$-approximation.

If there exists a new bin used in step 3. Let's denote the total used bins is ${ k+1 }$. That means when placing some piece, it can not fit in any fist ${ k }$ bins, which leads to the using of ${ (k+1)^{\text{th}} }$ bin. Hence, we have each first ${ k }$ bins must be occupied at least ${  1- \epsilon /2}$ size, otherwise, we can pack a small piece into it. Let's denote the input as ${ I }$, and the total size as ${ SIZE(I) = \sum{i=1}^n a_i }$. So, ${ SIZE(I) \geq \left(1-\frac{\epsilon}{2}\right) k  }$. Hence, we have 

<center>$$
 k \leq \frac{SIZE(I)}{\left(1-\frac{\epsilon}{2}\right)} \leq \left(1 + \frac{\epsilon / 2}{1 - \epsilon / 2} \right) SIZE(I) \leq \left(1 + \frac{\epsilon}{2 - \epsilon} \right) SIZE(I) \leq (1+\epsilon) SIZE(I)
$$</center>

And, we know the ${ OPT(I) \geq SIZE(I) }$ (we must use bins that is greater than the total size of all pieces.) Thus, we got 

<center>$$
k+1 \leq (1+\epsilon) SIZE(I) + 1 \leq (1+\epsilon) OPT(I) + 1
$$</center>

We prove the lemma 1. ${ \square }$

## Rounding Large Items

Given a integer parameter ${ k }$, we round the pieces in following way

1. Group the pieces as 
    
    * Group 1: first ${ k }$ largest pieces.

    * Group 2: second ${ k }$ largest pieces.

     &emsp;&emsp; ${ \vdots }$

    * Group i: ${ i^{\text{th}} }$ ${ k }$ largest pieces.

     &emsp;&emsp; ${ \vdots }$

    * Last group: remiaing ${ h }$ smallest pieces, where ${ h \leq k }$


