---
layout: article
title: Rounding and Dynamic Programming:Parallel Macines Job Scheduling
tags: Algorithm_Design_and_Analysis
aside:
  toc: true
sidebar:
  nav: Algorithm_Design_and_Analysis
---

From this blog, we will talk about "rounding data" strategy and dynamic programing applied in approximation algorithm in detail. And this blog will focus on the problem "scheduling jobs on identical parallel macines".

<!--more-->

# Polynomial time approximation Scheme (PTAS)

<b>Definition</b>: A polynomial time approximation scheme (PTAS) is a family of algorithms ${ A_{\epsilon} }$, where there is an algorithm for each ${ \epsilon \geq 0}$, such that ${ A_{\epsilon} }$ is a ${(1+\epsilon)  }$-approximation algorithm (for minimization problems) or a ${(1-\epsilon)  }$-approximation algorithm (for maximization problems)

We should noticed that

1. Running time depends on ${ \epsilon }$, for fixing ${ \epsilon }$, the runing time is a polynomial function of ${ n }$.

2. PTAS is stronger than other approximation, because there is no lower bound on the approximation ratio.

# Problem Definition and whole idea

## Definition of problem

Given ${ n }$ jobs and ${ m }$ machines each able to process one job at a time. 

Each job is associated with a process time ${ p_j }$. All jobs are available at time ${ 0 }$.

We need to assign all the ${ n }$ jobs to ${ m }$ machines. Denote the time that job ${ j }$ is completed as ${ C_j }$.

The objective is minimize the makespan ${ C_{max} = \max_j C_j }$.

## Big picture of idea

1. First we will split the jobs into two kinds -- long jobs and short jobs. We will show <b>if</b> we can schedule these long jobs with ${ (1+\epsilon) }$-approximation, then the result is <b>still ${ (1+\epsilon) }$-approximation</b> after scheduling these short jobs.

2. So we move to how to scheduling long jobs with ${ (1+\epsilon) }$-approximation. We can give a series time ${ T }$ and find an algorithm to <b>check if we can finish all the jobs in given time ${ T }$</b>. We select a series of ${ T }$ like ${ 1, (1+\epsilon), (1+\epsilon)^2, \cdots, (1+\epsilon)^n }$, and we find the minimum ${ T^\* }$ such that we can complete all the jobs, that will guarantee ${ (1+\epsilon) }$-approximation.

3. Now we need to find an algorithm to check if we can finish all the jobs in given time ${ T }$. We will take the <b>rounding strategy</b>. We will round process time of each job ${ j }$ as ${ \lfloor \frac{p_j}{\mu} \rfloor}$, so each process time is a multiple of ${ \mu }$, it's more easy to apply Dynamic Programming. And we also prove that <b>if</b> we can schedule these rounding jobs with ${ (1+\epsilon) }$-approximation, then the scheduling plan is <b>still ${ (1+\epsilon) }$-approximation</b> for original jobs. 

4. Then, we will design the <b>Dynamic Programming</b> algorithm for rounding jobs and prove it can be done in polynomial time.

# Long and short jobs

We can choose some ${ T^\* }$ such that ${ T^\* \leq OPT }$. We define a job as long job if ${ p_j \geq \epsilon T^\* }$, otherwise it is a short job.

Suppose we have an algorithm that can schedule long jobs within ${ (1+\epsilon)OPT }$. We can get following PTAS

* Step 1: Use "oracle" to schedule long jobs. 

* Step 2: Add the short jobs one by one, each time placing the job on the least loaded machine.

## aproximation analysis

<b>Lemma 1</b>ï¼šThe PTAS gives a sechedule of length ${ C_{max} = (1+\epsilon)OPT }$.

Proof. Let ${ \ell }$ be the job that finishes last in the schedule

* Case 1: Job ${ \ell }$ is a long job. Then, the makespan doesn't change after adding short jobs. So, ${ C_{max} = (1+\epsilon)OPT }$.

* Case 2: Job ${ \ell }$ is a long job. Let ${ S_{\ell} }$ be the start time of job ${ \ell }$. Because, all machines have load at least ${ S_{\ell} }$ (By step2, we place the job on the least loaded machine). Hence, ${ S_{\ell} }$ must be not greater than average process time, that is ${  S_{\ell}  \leq \sum_{j \neq \ell} p_j /m \leq \sum_{j} p_j /m }$. And we know the optimal makespan can not be less than average process time. Denote ${ P = \sum_{j} p_j }$, we get 

<center>$$
S_{\ell}  \leq \frac{P}{m} \leq OPT
$$</center>

Thus, we get 

<center>$$
C_{max} = S_{\ell} + p_{\ell} \leq OPT + p_{\ell} \leq OPT + \epsilon T^* \leq OPT + \epsilon OPT = (1+\epsilon) OPT
$$</center>

We prove lemma 1. ${ \square }$

## Runing time analysis

It's clear Step 2 can be done in polynomial time. We will show, by selecting appropriate ${ T^* }$ and assuming ${ m }$ is constant, we can finish Step 1 in polynomial time. 

<b>Lemma 2</b>: If ${ T^\* = \frac{P}{m}}$, then an optimal schedule of the long jobs can be found in ${ O(m^{m/\epsilon}) }$ time.

Proof. We noticed that the number of long jobs is no more than ${ \frac{P}{\epsilon T^\*} = P / \left(\epsilon \frac{P}{m}\right) = \frac{m}{\epsilon} }$. Each long job have ${ m }$ choices, so we can try all posible schedule in ${ O(m^{m/\epsilon}) }$ time. ${ \square }$

# Relaxed decision procedure

In the next part, we will give an algorithm ${ \mathcal{B}_{\epsilon} }$, that takes a time ${ T }$ as input. And algorithm ${ \mathcal{B}_{\epsilon} }$ either prove that no schedule of length ${ T }$, or else find a schedule of length ${  }$. Suppose we have the above algorithm, we will show how we can employ ${ \mathcal{B}_{\epsilon} }$ to solve the original problem.

## Bisection Search

<b>Here, we ask all the process times are integer.</b> First we give the lower and upper bound of ${ OPT }$. 

<center>$$
L_0 = \max \left\{ \lceil \sum_{j=1}^n p_j / m \rceil, \max_{j=1,\cdots,n}p_j \right\}
$$</center>

<center>$$
U_0 =  \lceil \sum_{j=1}^n p_j / m \rceil+ \max_{j=1,\cdots,n}p_j 
$$</center>

Note ${ L_0, U_0 }$ gets from [pervious blog](https://wu-haonan.github.io/2023/10/23/ADA_Lec_18.html) (${ OPT }$ makespan must be not less than max process time and average time on ${ m }$ machines. The upper bound can be get by considering the last complete job, which less and equal to average time plus max process time.) Through out the bisection search, we maintain two invariants (1) lower bound ${ L \leq OPT  }$, and (2) compute a schedule with makespan at most ${ (1+\epsilon)U }$.

In each iteration, the current interval is ${ [L,U] }$, we set ${ T=\lfloor (L+U)/2\rfloor }$, and run ${ \mathcal{B}_{\epsilon} }$.

1. If ${ \mathcal{B}_{\epsilon} }$ produces a schedule, then update ${ U \leftarrow T }$

2. Otherwise, ${ L \leftarrow T + 1 }$.

The ${ \mathcal{B}_{\epsilon} }$ terminates untill ${ L =U }$.

It's clear to check in each iteration, two variants are keeping correct. And we know the difference between ${ L_0 }$ and ${ U_0 }$ is at most ${\max_{j=1,\cdots,n}p_j  }$, denoted as ${ P_m }$. So ${ \mathcal{B}_{\epsilon} }$ stops in ${ O(\ln P_m) }$ steps. 

And, we know ${  L = U \leq OPT}$, and ${ \mathcal{B}_{\epsilon} }$ output schedule with makespan ${  (1+\epsilon)U =  (1+\epsilon)L \leq OPT }$.

# Rounding long jobs

Now we will give the algorithm ${ \mathcal{B}_{\epsilon} }$. First, we need to round the data and apply Dynamic Programming to solve the rounded data. In this section, we will show how to round and prove the approximation.

Let ${ \mu = \epsilon^2 T }$; Round the process time of each long job ${  j}$ as ${ p_j' = \lfloor \frac{p_j}{\mu} \rfloor \mu }$

<b> Claim 1</b>: If ${ T \geq OPT }$, and Dynamic Programming can give a schedule on rounded jobs in target time ${ T }$. ${ \mathcal{B}_{\epsilon} }$ will give an ${ (1+\epsilon)T }$ schedule. 

Proof. 

# Dynamic Programming of rounded long jobs