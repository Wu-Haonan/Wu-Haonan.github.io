---
layout: article
title: Randomized Algs:Occupancy Problems & Markov's and Chebyshev's inequalities
tags: Algorithm_Design_and_Analysis
aside:
  toc: true
sidebar:
  nav: Algorithm_Design_and_Analysis
---

This blog, we still talk about randomized algorithms. Today we will focus on some analysis tools in randomized algorithms.

<!--more-->

# Occupancy Problems

Imagine we have ${m}$ indistinguishable objects ("balls"), that we randomly assign to ${n}$ distinct classes ("bins").

- What is expected maximum number of balls in any bin?
- What is the expected number of bins with ${k}$ balls?

These are called occupancy problems.



Let ${m = n \geq 3}$, and for ${i = 1, \ldots, n}$ let random variable ${X_i}$ be the number of balls in the ${i}$th bin. And ${X_i}$ is a binomial distribution, ${X_i \sim B(n,\frac{1}{n})}$.

We want to find ${k}$ such that, with very high probability, no bin contains more than ${k}$ balls. Let ${\mathcal{E}_j(k)}$ be the event that bin ${j}$ contains at least ${k}$ balls $({X_j \geq k})$. 

First consider ${\mathcal{E}_i(k)}$,
$$
\begin{aligned}
Pr[X_i = j] &= \binom{n}{j} \left(\frac{1}{n}\right)^j \left(1 - \frac{1}{n}\right)^{n-j} \\
&\leq \binom{n}{j} \left(\frac{1}{n}\right)^j \\
&\leq \left(\frac{ne}{j}\right)^j \left(\frac{1}{n}\right)^j \\
&= \left(\frac{e}{j}\right)^j \\
\end{aligned}
$$

Note: in above scaling we use Stirling's approximation in step 3, that is ${n! = \sqrt{2 \pi n} \left(\frac{n}{e}\right)^n e^{c_n}, 0< c_n < \frac{1}{12n} }$. So we have
$$
\begin{aligned}
\binom{n}{j} &= \frac{n!}{j!(n-j)!} \\
&\leq \frac{n^j}{j!} \\
&\leq \frac{n^j}{\sqrt{2 \pi j} \left( \frac{j}{e}\right)^j}\\
&\leq \left(\frac{ne}{j}\right)^j
\end{aligned}
$$
Next, we have 
$$
\begin{aligned}
Pr[\mathcal{E}_i(k)] &\leq \sum_{j=k}^{n} \binom{n}{j} \left(\frac{1}{n}\right)^j \\
&\leq \sum_{j=k}^{n} \left(\frac{e}{j}\right)^j \\
&\leq \left(\frac{e}{k}\right)^k \left(1 + \frac{e}{k} + \left(\frac{e}{k}\right)^2 + \cdots + \left(\frac{e}{k}\right)^{n-k+1} \right) \\
&\leq \left(\frac{e}{k}\right)^k \left(\frac{1}{1 - \frac{e}{k}}\right)
\end{aligned}
$$
Note: in above scaling we use the union bound in step 1,
$$
\begin{aligned}
Pr[\mathcal{E}_i(k)] &= Pr\left[\cup_{j=k}^n [X_i = j]\right]\\
& \leq \sum_{j=k}^n Pr[X_i = j]\\
&\leq \sum_{j=k}^{n} \binom{n}{j} \left(\frac{1}{n}\right)^j \\
\end{aligned}
$$
