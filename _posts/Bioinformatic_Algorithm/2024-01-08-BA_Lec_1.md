---
layout: article
title: Lecture 1:Knuth-Morris-Pratt (KMP) algorithm
tags: Bioinformatic_Algorithm
aside:
  toc: true
sidebar:
  nav: Bioinformatic_Algorithm
---

At the beginning of our bioinformatic algorithms journal, we will focus on the similarity of strings. We we touch following aspects,

* Equality
  * Find occurrences of string $S$ in a given string $T$.
* Edit distance
  * Find edit distance between strings $S$ and $T$ (global alignment)
  * Find substring of $T$ with minimal edit distance to given string $S$ (local alignment)
* Probability
  * Construct probability model that best describes a given set of strings. 
  * Check if a given strings is likely to be of the same type. 



Today, we will introduce the algorithm for first problem: find all occurrences of a string $P$ (called pattern string) in a given string $T$ as a substring. 

<!--more-->

# Naïve algorithm

Given a pattern string $P$ and a text string $T$, we denote $m$ is the pattern size and $n$ is the text size ($m \leq n$). We can immediately get a naïve idea, that is we can slide text string $T$ with window size of $m$ from end to end. And check each substring with length $m$  if equals to pattern string $P$. Here is a pseudocode

{% highlight pseudocode linenos %}
NaïveMatch(P,T)
	Ocurrences = [] // record initial positions in T
	for i = 0, 1, ..., n-m
		j = 0
		while j < m and P[j] = T[i+j]
			j += 1
		if j == m
			Ocurrences.append(i)
{% endhighlight %}

It's oblivious that the running time is $\mathcal{O}(mn)$. It's not an efficient way, but we analyze it to see what happens and get some new idea.

<p align="center">
    <img src="/post_image/Bioinformatic_Algorithm/Naive_pattern_match.png" width="70%">
</p>
If you check the two yellow boxes in the figure, you will find the they have exactly the same content. It's easy to get, because in this box we first get a match in $T$ and slide $P$ to try further alignments. So, the alignment pattern must be identical. Furthermore, if you check the blue box, it's also identical. Because, given a prefix of $P$ denoted as $S$ including $P$ itself, the alignment result of suffix of $S$ and prefix of $S$ is identical. Hence, we get an idea, we don't need to compute these alignment repeatedly. We can directly record these alignment and jump to next position that we don't know. Okay, I know now it's a little confusing for my description. I will give the algorithm as below and explain the key idea of the algorithm again. 




# KMP algorithm



Zig zag
